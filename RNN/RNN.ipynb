{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272c59a6",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "MUST READ ARTICLE:\n",
    "https://medium.com/@sachinsoni600517/recurrent-neural-networks-rnn-from-basic-to-advanced-1da22aafa009\n",
    "\n",
    "EXAMPLE STOCK PREDICTION\n",
    "https://www.kaggle.com/code/rodsaldanha/stock-prediction-pytorch\n",
    "https://medium.com/swlh/stock-price-prediction-with-pytorch-37f52ae84632\n",
    "\n",
    "An RNN, or Recurrent Neural Network, is a type of artificial neural network designed for processing sequences of data. Unlike traditional feedforward neural networks, which process data in fixed-size input vectors, RNNs are capable of handling input sequences of variable length, making them well-suited for tasks involving time series data, natural language processing, and other sequential data types.\n",
    "\n",
    "![alt text](https://pythongeeks.org/wp-content/uploads/2022/02/rnn-block.webp)\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_zdmcCu76MUmw87P.png)\n",
    "\n",
    "The key feature of RNNs is their ability to maintain a hidden state that captures information from previous time steps in the sequence. This hidden state is updated as new inputs are processed, allowing the network to capture temporal dependencies and context within the sequence.\n",
    "\n",
    "Here's a simplified explanation of how an RNN works:\n",
    "\n",
    "- Initialization: At the start of processing a sequence, the RNN initializes its hidden state to a fixed size vector, typically containing zeros.\n",
    "\n",
    "- Sequential Processing: The RNN processes the input sequence one element at a time, such as one word in a sentence or one data point in a time series. At each time step, it takes the current input and combines it with the previous hidden state to produce an output and update the hidden state.\n",
    "\n",
    "- Recurrent Connections: The recurrent connections in the RNN allow information to flow from one time step to the next, enabling the network to capture dependencies and patterns within the sequence.\n",
    "\n",
    "RNNs have been used in various applications, including natural language processing (e.g., language modeling and machine translation), speech recognition, time series analysis, and more. However, they have some limitations, such as difficulty in capturing long-range dependencies, which has led to the development of more advanced recurrent architectures like Long Short-Term Memory (LSTM) networks and Gated Recurrent Unit (GRU) networks, which are designed to address some of these issues.\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:1400/1*xs2EgGPGlpWrSW4zUANYXA.png)\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:1194/1*B0q2ZLsUUw31eEImeVf3PQ.png)\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:2000/format:webp/1*ajbaACJsBtkZEq77jUQlSQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c4055f",
   "metadata": {},
   "source": [
    "As we can see, the calculations at each time step consider the context of the previous time steps in the form of the hidden state. Being able to use this contextual information from previous inputs is the key essence to RNNs’ success in sequential problems.\n",
    "\n",
    "While it may seem that a different RNN cell is being used at each time step in the graphics, the underlying principle of Recurrent Neural Networks is that the RNN cell is actually the exact same one and reused throughout.\n",
    "\n",
    "\n",
    "## Processing RNN Outputs?\n",
    "\n",
    "![alt text](https://cs231n.github.io/assets/rnn/types.png)\n",
    "\n",
    "You might be wondering, which portion of the RNN do I extract my output from? This really depends on what your use case is. For example, if you’re using the RNN for a classification task, you’ll only need one final output after passing in all the input - a vector representing the class probability scores. In another case, if you’re doing text generation based on the previous character/word, you’ll need an output at every single time step.\n",
    "\n",
    "This is where RNNs are really flexible and can adapt to your needs. As seen in the image above, your input and output size can come in different forms, yet they can still be fed into and extracted from the RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a6140",
   "metadata": {},
   "source": [
    "For the case where you’ll only need a single output from the whole process, getting that output can be fairly straightforward as you can easily take the output produced by the last RNN cell in the sequence. As this final output has already undergone calculations through all the previous cells, the context of all the previous inputs has been captured. This means that the final result is indeed dependent on all the previous computations and inputs.\n",
    "\n",
    "\n",
    "For the second case where you’ll need output information from the intermediate time steps, this information can be taken from the hidden state produced at each step as shown in the figure above. The output produced can also be fed back into the model at the next time step if necessary.\n",
    "\n",
    "Of course, the type of output that you can obtain from an RNN model is not limited to just these two cases. There are other methods such as Sequence-To-Sequence translation where the output is only produced in a sequence after all the input has been passed through.\n",
    "\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:1000/format:webp/1*bxfNRcWMs0xZ-3TDScqukQ.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f5813",
   "metadata": {},
   "source": [
    "## Code:\n",
    "\n",
    "We will be building and training a basic character-level Recurrent Neural Network (RNN) to classify words. A character-level RNN reads words as a series of characters - outputting a prediction and “hidden state” at each step, feeding its previous hidden state into each next step. We take the final prediction to be the output, i.e. which class the word belongs to.\n",
    "\n",
    "Specifically, we’ll train on a few thousand surnames from 18 languages of origin, and predict which language a name is from based on the spelling:\n",
    "\n",
    "\n",
    "Dataset Link: https://download.pytorch.org/tutorial/data.zip\n",
    "\n",
    "Included in the data/names directory are 18 text files named as [Language].txt. Each file contains a bunch of names, one name per line, mostly romanized (but we still need to convert from Unicode to ASCII).\n",
    "\n",
    "We’ll end up with a dictionary of lists of names per language, {language: [names ...]}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "57fa4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas\n",
    "import os\n",
    "import glob as glob\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from string import ascii_letters\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "707600ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d6432f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arabic.txt'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=os.listdir(r\"D:\\Datasets\\RNN_data\\data\\names\")\n",
    "filename[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "de405574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e75428c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic.txt',\n",
       " 'Chinese.txt',\n",
       " 'Czech.txt',\n",
       " 'Dutch.txt',\n",
       " 'English.txt',\n",
       " 'French.txt',\n",
       " 'German.txt',\n",
       " 'Greek.txt',\n",
       " 'Irish.txt',\n",
       " 'Italian.txt',\n",
       " 'Japanese.txt',\n",
       " 'Korean.txt',\n",
       " 'Polish.txt',\n",
       " 'Portuguese.txt',\n",
       " 'Russian.txt',\n",
       " 'Scottish.txt',\n",
       " 'Spanish.txt',\n",
       " 'Vietnamese.txt']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename[0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "576368ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic', 'txt']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename[0].split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "91af823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Arabic\n",
      "1 Chinese\n",
      "2 Czech\n",
      "3 Dutch\n",
      "4 English\n",
      "5 French\n",
      "6 German\n",
      "7 Greek\n",
      "8 Irish\n",
      "9 Italian\n",
      "10 Japanese\n",
      "11 Korean\n",
      "12 Polish\n",
      "13 Portuguese\n",
      "14 Russian\n",
      "15 Scottish\n",
      "16 Spanish\n",
      "17 Vietnamese\n"
     ]
    }
   ],
   "source": [
    "for idx,file in enumerate(filename):\n",
    "    print(idx,file.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9e692274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,\n",
       " {'Arabic': tensor(0.),\n",
       "  'Chinese': tensor(1.),\n",
       "  'Czech': tensor(2.),\n",
       "  'Dutch': tensor(3.),\n",
       "  'English': tensor(4.),\n",
       "  'French': tensor(5.),\n",
       "  'German': tensor(6.),\n",
       "  'Greek': tensor(7.),\n",
       "  'Irish': tensor(8.),\n",
       "  'Italian': tensor(9.),\n",
       "  'Japanese': tensor(10.),\n",
       "  'Korean': tensor(11.),\n",
       "  'Polish': tensor(12.),\n",
       "  'Portuguese': tensor(13.),\n",
       "  'Russian': tensor(14.),\n",
       "  'Scottish': tensor(15.),\n",
       "  'Spanish': tensor(16.),\n",
       "  'Vietnamese': tensor(17.)})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang2label={\n",
    "    name.split(\".\")[0]:torch.tensor(i,dtype=torch.float32) for i,name in enumerate(filename)\n",
    "}\n",
    "len(lang2label),lang2label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2a8c98d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Slusarski'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unidecode(\"Ślusàrski\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "03d08ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "84eb2104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52,\n",
       " {'a': 0,\n",
       "  'b': 1,\n",
       "  'c': 2,\n",
       "  'd': 3,\n",
       "  'e': 4,\n",
       "  'f': 5,\n",
       "  'g': 6,\n",
       "  'h': 7,\n",
       "  'i': 8,\n",
       "  'j': 9,\n",
       "  'k': 10,\n",
       "  'l': 11,\n",
       "  'm': 12,\n",
       "  'n': 13,\n",
       "  'o': 14,\n",
       "  'p': 15,\n",
       "  'q': 16,\n",
       "  'r': 17,\n",
       "  's': 18,\n",
       "  't': 19,\n",
       "  'u': 20,\n",
       "  'v': 21,\n",
       "  'w': 22,\n",
       "  'x': 23,\n",
       "  'y': 24,\n",
       "  'z': 25,\n",
       "  'A': 26,\n",
       "  'B': 27,\n",
       "  'C': 28,\n",
       "  'D': 29,\n",
       "  'E': 30,\n",
       "  'F': 31,\n",
       "  'G': 32,\n",
       "  'H': 33,\n",
       "  'I': 34,\n",
       "  'J': 35,\n",
       "  'K': 36,\n",
       "  'L': 37,\n",
       "  'M': 38,\n",
       "  'N': 39,\n",
       "  'O': 40,\n",
       "  'P': 41,\n",
       "  'Q': 42,\n",
       "  'R': 43,\n",
       "  'S': 44,\n",
       "  'T': 45,\n",
       "  'U': 46,\n",
       "  'V': 47,\n",
       "  'W': 48,\n",
       "  'X': 49,\n",
       "  'Y': 50,\n",
       "  'Z': 51})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx={letter: i for i,letter in enumerate(ascii_letters)}\n",
    "len(char2idx),char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7040c368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector=torch.zeros(1,52)\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8ffceb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=torch.zeros(2,1,52)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "af90a898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 52])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e1d1d5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[0][char2idx[\"A\"]]=1\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a501e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2vector(name):\n",
    "    vector=torch.zeros(len(name),1,52)\n",
    "    for i,names in enumerate(name):\n",
    "        vector[i][0][char2idx[names]]=1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "03bc4ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]]]),\n",
       " torch.Size([5, 1, 52]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2vector(\"khush\"),name2vector(\"khush\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e911fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lang=[]\n",
    "tensor_name=[]\n",
    "data_dir=r\"D:\\Datasets\\RNN_data\\data\\names\"\n",
    "for file in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir,file)) as f:\n",
    "        lang=file.split(\".\")[0]\n",
    "        names=[unidecode(line.strip()) for line in f]\n",
    "        for name in names:\n",
    "            try:\n",
    "                tensor_name.append(name2vector(name))\n",
    "                target_lang.append(lang2label[lang])\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cd302dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19892, 19892)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_lang),len(tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "93fcb633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.]]]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_lang[2],tensor_name[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5ac89150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19892"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "91e96386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19892"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c3800d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cee2e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here name data and language label are stored in different list and are in different forms to make sure they are corretly aligned i.e one training smple has its own output \n",
    "#we first split the indexes so the data get properly splitted with correct labels and it is safe to use it that way otherwise it may lead to wrong labels\n",
    "train_idx,test_idx=train_test_split(range(len(target_lang)),test_size=0.2,shuffle=True,stratify=target_lang,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0bd2922e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15913, 3979)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx),len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "933c32f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15913, 3979)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset=[(tensor_name[i],target_lang[i]) for i in train_idx]\n",
    "test_dataset=[(tensor_name[i],target_lang[i]) for i in test_idx]\n",
    "len(train_dataset),len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6d5d119b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9, 1, 52]), torch.Size([5, 1, 52]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][0].shape,test_dataset[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33229168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9b5100cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self,hidden_size,input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.input_2_hidden=nn.Linear(\n",
    "            in_features=input_size,\n",
    "            out_features=hidden_size,\n",
    "        )\n",
    "        self.hidden_2_hidden=nn.Linear(\n",
    "            in_features=hidden_size,\n",
    "            out_features=hidden_size,\n",
    "        )\n",
    "        self.hidden_2_output=nn.Linear(\n",
    "            in_features=hidden_size,\n",
    "            out_features=output_size,\n",
    "        )\n",
    "    \n",
    "    def forward(self,input,past):\n",
    "        past_input_combined=nn.functional.relu(self.input_2_hidden(input)+self.hidden_2_hidden(past))\n",
    "        outputs=self.hidden_2_output(past_input_combined)\n",
    "        output=nn.functional.softmax(outputs,dim=1)\n",
    "        return output,past_input_combined\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f8784e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyRNN(\n",
       "  (input_2_hidden): Linear(in_features=52, out_features=64, bias=True)\n",
       "  (hidden_2_hidden): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (hidden_2_output): Linear(in_features=64, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=MyRNN(64,len(char2idx),len(lang2label))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2140bbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0521, 0.0488, 0.0650,  ..., 0.0387, 0.0474, 0.0582],\n",
       "         [0.0500, 0.0491, 0.0630,  ..., 0.0419, 0.0481, 0.0612],\n",
       "         [0.0420, 0.0542, 0.0567,  ..., 0.0390, 0.0495, 0.0587],\n",
       "         ...,\n",
       "         [0.0494, 0.0477, 0.0601,  ..., 0.0450, 0.0544, 0.0583],\n",
       "         [0.0537, 0.0541, 0.0606,  ..., 0.0366, 0.0473, 0.0671],\n",
       "         [0.0495, 0.0557, 0.0604,  ..., 0.0375, 0.0491, 0.0624]],\n",
       "        grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.0000, 0.0000, 0.1391,  ..., 0.2547, 0.5531, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.5145, 0.5568, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.2749, 0.8608, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.5272, 0.7663, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0861,  ..., 0.4281, 0.7161, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.1017, 0.8362, 0.0000]],\n",
       "        grad_fn=<ReluBackward0>))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=torch.rand(1,52)\n",
    "test1=torch.rand(64,64)\n",
    "test.shape\n",
    "model(test,test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4af4062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a9e862a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyRNN                                    [1, 18]                   --\n",
       "├─Linear: 1-1                            [1, 64]                   3,392\n",
       "├─Linear: 1-2                            [1, 64]                   4,160\n",
       "├─Linear: 1-3                            [1, 18]                   1,170\n",
       "==========================================================================================\n",
       "Total params: 8,722\n",
       "Trainable params: 8,722\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.01\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.04\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,input_size=((1,52),(1,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "695e3489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0634, 0.0636, 0.0559, 0.0567, 0.0546, 0.0528, 0.0540, 0.0636, 0.0567,\n",
       "          0.0556, 0.0570, 0.0524, 0.0593, 0.0500, 0.0531, 0.0496, 0.0545, 0.0473]],\n",
       "        grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.0000, 0.1073, 0.0000, 0.1696, 0.0000, 0.0954, 0.0000, 0.0631, 0.0000,\n",
       "          0.0000, 0.0924, 0.0347, 0.0056, 0.0028, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1187, 0.0194, 0.0941, 0.1808, 0.0095, 0.1300, 0.0000, 0.2194, 0.0257,\n",
       "          0.0975, 0.0000, 0.3151, 0.1223, 0.1194, 0.0727, 0.0602, 0.0000, 0.0056,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0743, 0.0000, 0.0000, 0.2130, 0.0000, 0.1020, 0.0000, 0.1174,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1387, 0.0387, 0.0557, 0.0000, 0.0184,\n",
       "          0.0000]], grad_fn=<ReluBackward0>))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first index represent the id of values stored in tuple of (name,lamg), second reprsents the 1 of 1x52 and third represents the character at that index\n",
    "model(train_dataset[0][0][5],model.init_hidden())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "69fc3e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b89253a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss().to(device)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "45187405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Step [500/15913], Loss: 2.9815\n",
      "Epoch [1/7], Step [1000/15913], Loss: 2.9814\n",
      "Epoch [1/7], Step [1500/15913], Loss: 1.9815\n",
      "Epoch [1/7], Step [2000/15913], Loss: 2.9445\n",
      "Epoch [1/7], Step [2500/15913], Loss: 1.9815\n",
      "Epoch [1/7], Step [3000/15913], Loss: 2.9686\n",
      "Epoch [1/7], Step [3500/15913], Loss: 2.9630\n",
      "Epoch [1/7], Step [4000/15913], Loss: 2.0084\n",
      "Epoch [1/7], Step [4500/15913], Loss: 2.1030\n",
      "Epoch [1/7], Step [5000/15913], Loss: 2.7692\n",
      "Epoch [1/7], Step [5500/15913], Loss: 2.8363\n",
      "Epoch [1/7], Step [6000/15913], Loss: 1.9815\n",
      "Epoch [1/7], Step [6500/15913], Loss: 1.9972\n",
      "Epoch [1/7], Step [7000/15913], Loss: 2.3234\n",
      "Epoch [1/7], Step [7500/15913], Loss: 1.9815\n",
      "Epoch [1/7], Step [8000/15913], Loss: 2.8809\n",
      "Epoch [1/7], Step [8500/15913], Loss: 2.0352\n",
      "Epoch [1/7], Step [9000/15913], Loss: 2.9781\n",
      "Epoch [1/7], Step [9500/15913], Loss: 1.9815\n",
      "Epoch [1/7], Step [10000/15913], Loss: 1.9815\n",
      "Epoch [1/7], Step [10500/15913], Loss: 2.2731\n",
      "Epoch [1/7], Step [11000/15913], Loss: 2.8061\n",
      "Epoch [1/7], Step [11500/15913], Loss: 2.9582\n",
      "Epoch [1/7], Step [12000/15913], Loss: 1.9817\n",
      "Epoch [1/7], Step [12500/15913], Loss: 1.9815\n",
      "Epoch [1/7], Step [13000/15913], Loss: 1.9822\n",
      "Epoch [1/7], Step [13500/15913], Loss: 1.9815\n",
      "Epoch [1/7], Step [14000/15913], Loss: 1.9815\n",
      "Epoch [1/7], Step [14500/15913], Loss: 2.9803\n",
      "Epoch [1/7], Step [15000/15913], Loss: 1.9816\n",
      "Epoch [1/7], Step [15500/15913], Loss: 1.9857\n",
      "Epoch [2/7], Step [500/15913], Loss: 2.9611\n",
      "Epoch [2/7], Step [1000/15913], Loss: 2.0831\n",
      "Epoch [2/7], Step [1500/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [2000/15913], Loss: 2.9811\n",
      "Epoch [2/7], Step [2500/15913], Loss: 2.4998\n",
      "Epoch [2/7], Step [3000/15913], Loss: 2.9534\n",
      "Epoch [2/7], Step [3500/15913], Loss: 2.9795\n",
      "Epoch [2/7], Step [4000/15913], Loss: 1.9932\n",
      "Epoch [2/7], Step [4500/15913], Loss: 2.0669\n",
      "Epoch [2/7], Step [5000/15913], Loss: 1.9878\n",
      "Epoch [2/7], Step [5500/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [6000/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [6500/15913], Loss: 1.9922\n",
      "Epoch [2/7], Step [7000/15913], Loss: 1.9862\n",
      "Epoch [2/7], Step [7500/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [8000/15913], Loss: 1.9816\n",
      "Epoch [2/7], Step [8500/15913], Loss: 1.9829\n",
      "Epoch [2/7], Step [9000/15913], Loss: 2.9808\n",
      "Epoch [2/7], Step [9500/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [10000/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [10500/15913], Loss: 2.6203\n",
      "Epoch [2/7], Step [11000/15913], Loss: 1.9883\n",
      "Epoch [2/7], Step [11500/15913], Loss: 2.7589\n",
      "Epoch [2/7], Step [12000/15913], Loss: 1.9876\n",
      "Epoch [2/7], Step [12500/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [13000/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [13500/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [14000/15913], Loss: 1.9815\n",
      "Epoch [2/7], Step [14500/15913], Loss: 2.9376\n",
      "Epoch [2/7], Step [15000/15913], Loss: 2.0025\n",
      "Epoch [2/7], Step [15500/15913], Loss: 1.9816\n",
      "Epoch [3/7], Step [500/15913], Loss: 2.0084\n",
      "Epoch [3/7], Step [1000/15913], Loss: 1.9949\n",
      "Epoch [3/7], Step [1500/15913], Loss: 1.9815\n",
      "Epoch [3/7], Step [2000/15913], Loss: 2.9801\n",
      "Epoch [3/7], Step [2500/15913], Loss: 2.9228\n",
      "Epoch [3/7], Step [3000/15913], Loss: 2.9693\n",
      "Epoch [3/7], Step [3500/15913], Loss: 2.9815\n",
      "Epoch [3/7], Step [4000/15913], Loss: 1.9844\n",
      "Epoch [3/7], Step [4500/15913], Loss: 1.9851\n",
      "Epoch [3/7], Step [5000/15913], Loss: 1.9816\n",
      "Epoch [3/7], Step [5500/15913], Loss: 2.0620\n",
      "Epoch [3/7], Step [6000/15913], Loss: 1.9815\n",
      "Epoch [3/7], Step [6500/15913], Loss: 1.9815\n",
      "Epoch [3/7], Step [7000/15913], Loss: 1.9828\n",
      "Epoch [3/7], Step [7500/15913], Loss: 1.9815\n",
      "Epoch [3/7], Step [8000/15913], Loss: 1.9816\n",
      "Epoch [3/7], Step [8500/15913], Loss: 1.9817\n",
      "Epoch [3/7], Step [9000/15913], Loss: 2.9549\n",
      "Epoch [3/7], Step [9500/15913], Loss: 1.9815\n",
      "Epoch [3/7], Step [10000/15913], Loss: 1.9815\n",
      "Epoch [3/7], Step [10500/15913], Loss: 1.9826\n",
      "Epoch [3/7], Step [11000/15913], Loss: 2.0519\n",
      "Epoch [3/7], Step [11500/15913], Loss: 2.9662\n",
      "Epoch [3/7], Step [12000/15913], Loss: 1.9833\n",
      "Epoch [3/7], Step [12500/15913], Loss: 1.9815\n",
      "Epoch [3/7], Step [13000/15913], Loss: 1.9816\n",
      "Epoch [3/7], Step [13500/15913], Loss: 1.9815\n",
      "Epoch [3/7], Step [14000/15913], Loss: 1.9815\n",
      "Epoch [3/7], Step [14500/15913], Loss: 2.9815\n",
      "Epoch [3/7], Step [15000/15913], Loss: 1.9915\n",
      "Epoch [3/7], Step [15500/15913], Loss: 1.9816\n",
      "Epoch [4/7], Step [500/15913], Loss: 1.9820\n",
      "Epoch [4/7], Step [1000/15913], Loss: 1.9921\n",
      "Epoch [4/7], Step [1500/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [2000/15913], Loss: 2.9814\n",
      "Epoch [4/7], Step [2500/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [3000/15913], Loss: 2.9710\n",
      "Epoch [4/7], Step [3500/15913], Loss: 2.9815\n",
      "Epoch [4/7], Step [4000/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [4500/15913], Loss: 1.9842\n",
      "Epoch [4/7], Step [5000/15913], Loss: 1.9816\n",
      "Epoch [4/7], Step [5500/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [6000/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [6500/15913], Loss: 2.9309\n",
      "Epoch [4/7], Step [7000/15913], Loss: 1.9816\n",
      "Epoch [4/7], Step [7500/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [8000/15913], Loss: 1.9816\n",
      "Epoch [4/7], Step [8500/15913], Loss: 1.9817\n",
      "Epoch [4/7], Step [9000/15913], Loss: 2.9815\n",
      "Epoch [4/7], Step [9500/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [10000/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [10500/15913], Loss: 1.9816\n",
      "Epoch [4/7], Step [11000/15913], Loss: 1.9816\n",
      "Epoch [4/7], Step [11500/15913], Loss: 2.7387\n",
      "Epoch [4/7], Step [12000/15913], Loss: 1.9817\n",
      "Epoch [4/7], Step [12500/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [13000/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [13500/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [14000/15913], Loss: 1.9815\n",
      "Epoch [4/7], Step [14500/15913], Loss: 2.9815\n",
      "Epoch [4/7], Step [15000/15913], Loss: 2.9815\n",
      "Epoch [4/7], Step [15500/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [500/15913], Loss: 1.9817\n",
      "Epoch [5/7], Step [1000/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [1500/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [2000/15913], Loss: 2.9814\n",
      "Epoch [5/7], Step [2500/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [3000/15913], Loss: 2.9658\n",
      "Epoch [5/7], Step [3500/15913], Loss: 2.9815\n",
      "Epoch [5/7], Step [4000/15913], Loss: 1.9817\n",
      "Epoch [5/7], Step [4500/15913], Loss: 1.9928\n",
      "Epoch [5/7], Step [5000/15913], Loss: 1.9816\n",
      "Epoch [5/7], Step [5500/15913], Loss: 1.9816\n",
      "Epoch [5/7], Step [6000/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [6500/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [7000/15913], Loss: 1.9820\n",
      "Epoch [5/7], Step [7500/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [8000/15913], Loss: 1.9816\n",
      "Epoch [5/7], Step [8500/15913], Loss: 1.9817\n",
      "Epoch [5/7], Step [9000/15913], Loss: 2.9795\n",
      "Epoch [5/7], Step [9500/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [10000/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [10500/15913], Loss: 1.9816\n",
      "Epoch [5/7], Step [11000/15913], Loss: 1.9816\n",
      "Epoch [5/7], Step [11500/15913], Loss: 2.5405\n",
      "Epoch [5/7], Step [12000/15913], Loss: 1.9816\n",
      "Epoch [5/7], Step [12500/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [13000/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [13500/15913], Loss: 1.9815\n",
      "Epoch [5/7], Step [14000/15913], Loss: 1.9905\n",
      "Epoch [5/7], Step [14500/15913], Loss: 2.9815\n",
      "Epoch [5/7], Step [15000/15913], Loss: 2.9815\n",
      "Epoch [5/7], Step [15500/15913], Loss: 1.9817\n",
      "Epoch [6/7], Step [500/15913], Loss: 1.9817\n",
      "Epoch [6/7], Step [1000/15913], Loss: 2.2417\n",
      "Epoch [6/7], Step [1500/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [2000/15913], Loss: 2.9815\n",
      "Epoch [6/7], Step [2500/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [3000/15913], Loss: 2.9755\n",
      "Epoch [6/7], Step [3500/15913], Loss: 2.9815\n",
      "Epoch [6/7], Step [4000/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [4500/15913], Loss: 1.9874\n",
      "Epoch [6/7], Step [5000/15913], Loss: 1.9816\n",
      "Epoch [6/7], Step [5500/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [6000/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [6500/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [7000/15913], Loss: 1.9816\n",
      "Epoch [6/7], Step [7500/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [8000/15913], Loss: 1.9816\n",
      "Epoch [6/7], Step [8500/15913], Loss: 1.9818\n",
      "Epoch [6/7], Step [9000/15913], Loss: 2.9647\n",
      "Epoch [6/7], Step [9500/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [10000/15913], Loss: 1.9816\n",
      "Epoch [6/7], Step [10500/15913], Loss: 1.9816\n",
      "Epoch [6/7], Step [11000/15913], Loss: 1.9816\n",
      "Epoch [6/7], Step [11500/15913], Loss: 2.9290\n",
      "Epoch [6/7], Step [12000/15913], Loss: 1.9817\n",
      "Epoch [6/7], Step [12500/15913], Loss: 2.8272\n",
      "Epoch [6/7], Step [13000/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [13500/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [14000/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [14500/15913], Loss: 2.9815\n",
      "Epoch [6/7], Step [15000/15913], Loss: 1.9815\n",
      "Epoch [6/7], Step [15500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [500/15913], Loss: 1.9821\n",
      "Epoch [7/7], Step [1000/15913], Loss: 1.9856\n",
      "Epoch [7/7], Step [1500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [2000/15913], Loss: 2.9815\n",
      "Epoch [7/7], Step [2500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [3000/15913], Loss: 2.9795\n",
      "Epoch [7/7], Step [3500/15913], Loss: 2.9815\n",
      "Epoch [7/7], Step [4000/15913], Loss: 1.9817\n",
      "Epoch [7/7], Step [4500/15913], Loss: 2.1017\n",
      "Epoch [7/7], Step [5000/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [5500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [6000/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [6500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [7000/15913], Loss: 1.9829\n",
      "Epoch [7/7], Step [7500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [8000/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [8500/15913], Loss: 1.9816\n",
      "Epoch [7/7], Step [9000/15913], Loss: 2.9671\n",
      "Epoch [7/7], Step [9500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [10000/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [10500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [11000/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [11500/15913], Loss: 2.8885\n",
      "Epoch [7/7], Step [12000/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [12500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [13000/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [13500/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [14000/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [14500/15913], Loss: 2.9815\n",
      "Epoch [7/7], Step [15000/15913], Loss: 1.9815\n",
      "Epoch [7/7], Step [15500/15913], Loss: 1.9820\n"
     ]
    }
   ],
   "source": [
    "num_epoch=7\n",
    "print_interval=500\n",
    "model.to(device)\n",
    "for epoch in range(num_epoch):\n",
    "    for i,(name,label) in enumerate(train_dataset):\n",
    "        hidden_state=model.init_hidden()\n",
    "        hidden_state.to(device)\n",
    "        name=name.to(device)\n",
    "        label=label.long().to(device)\n",
    "        for char in name:\n",
    "            #char dim = 1x52\n",
    "            output,hidden_state=model(char,hidden_state)\n",
    "        \n",
    "        loss=loss_fn(output,label.unsqueeze(0))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % print_interval==0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epoch}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                #.item() to convert tensor to int\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "70db2d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 73.6617\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "with torch.inference_mode():\n",
    "    for name,label in test_dataset:\n",
    "        hidden_state=model.init_hidden()\n",
    "        hidden_state.to(device)\n",
    "        name=name.to(device)\n",
    "        label=label.long().unsqueeze(0).to(device)\n",
    "        for char in name:\n",
    "            output,hidden_state=model(char,hidden_state)\n",
    "        _,pred=torch.max(output,dim=1)\n",
    "        correct+=torch.sum(pred==label)\n",
    "print(f\"Accuracy : {correct/len(test_dataset)*100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e8c3090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arabic', tensor(0.))\n",
      "('Chinese', tensor(1.))\n",
      "('Czech', tensor(2.))\n",
      "('Dutch', tensor(3.))\n",
      "('English', tensor(4.))\n",
      "('French', tensor(5.))\n",
      "('German', tensor(6.))\n",
      "('Greek', tensor(7.))\n",
      "('Irish', tensor(8.))\n",
      "('Italian', tensor(9.))\n",
      "('Japanese', tensor(10.))\n",
      "('Korean', tensor(11.))\n",
      "('Polish', tensor(12.))\n",
      "('Portuguese', tensor(13.))\n",
      "('Russian', tensor(14.))\n",
      "('Scottish', tensor(15.))\n",
      "('Spanish', tensor(16.))\n",
      "('Vietnamese', tensor(17.))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 'Arabic',\n",
       " 1.0: 'Chinese',\n",
       " 2.0: 'Czech',\n",
       " 3.0: 'Dutch',\n",
       " 4.0: 'English',\n",
       " 5.0: 'French',\n",
       " 6.0: 'German',\n",
       " 7.0: 'Greek',\n",
       " 8.0: 'Irish',\n",
       " 9.0: 'Italian',\n",
       " 10.0: 'Japanese',\n",
       " 11.0: 'Korean',\n",
       " 12.0: 'Polish',\n",
       " 13.0: 'Portuguese',\n",
       " 14.0: 'Russian',\n",
       " 15.0: 'Scottish',\n",
       " 16.0: 'Spanish',\n",
       " 17.0: 'Vietnamese'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for lang in lang2label.items():\n",
    "    print(lang)\n",
    "label2lang={label.item():lang for lang,label in lang2label.items()}\n",
    "label2lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4f758c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2lang={label.item():lang for lang,label in lang2label.items()}\n",
    "def myrnnpredict(name):\n",
    "    tensor_name=name2vector(name)\n",
    "    with torch.inference_mode():\n",
    "        tensor_name=tensor_name.to(device)\n",
    "        hidden_state=model.init_hidden()\n",
    "        hidden_state=hidden_state.to(device)\n",
    "        for char in tensor_name:\n",
    "            output,hidden_state=model(char,hidden_state)\n",
    "        _,pred=torch.max(output,dim=1)\n",
    "        model.train()\n",
    "    return label2lang[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b88e0b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Russian'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myrnnpredict(\"zhang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b1d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b2a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
